---
title: "Rapport - You suck at IF36"
author: "Alban Souchard, Paul Fernandez, Thomas Matamba, Klimentiy Mirek"
date: "2025-04-23"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

plotnum <- 0
knit_print.ggplot <- function(x, options) {
  plotnum <<- plotnum + 1
  ggsave(sprintf("graphics/graph-%02d.png", plotnum), x +
    theme(
      panel.background = element_rect(fill = "transparent"),
      plot.background = element_rect(fill = "transparent", color = NA),
      legend.background = element_rect(fill = "transparent", colour = "transparent", linetype = "blank"),
      legend.box.background = element_rect(fill = "transparent", colour = "transparent", linetype = "blank")
    ), bg = "transparent")
  print(x)
}
# If having trouble running knit, comment the function below (if it requires the "orca" package)
knit_print.plotly <- function(x, options, ...) {
  plotnum <<- plotnum + 1
  orca(x %>% layout(
    plot_bgcolor = "rgba(0,0,0,0)",
    paper_bgcolor = "rgba(0,0,0,0)"
  ), sprintf("graphics/graph-%02d.png", plotnum), scale = 10)
  if (!is.null(options$fig.width)) x$width <- options$fig.width * 96
  if (!is.null(options$fig.height)) x$height <- options$fig.height * 96
  htmlwidgets:::knit_print.htmlwidget(x, options, ...)
}
# This saves the radarchart to png. Uncomment both lines par(bg=NA) and save_plot() to generate export
save_plot <- function() {
  plotnum <<- plotnum + 1
  p <- recordPlot()
  png(sprintf("graphics/graph-%02d.png", plotnum), bg = "transparent", res = 288, width = 1920, height = 1920)
  replayPlot(p)
  dev.off()
}
```

# Introduction

Dans le cadre du projet pour l’UE IF36, “Visualiser des données”, notre groupe utilisera le jeu de données suivant : “Spotify and Youtube, Statistics for the Top 10 songs of various spotify artists and their yt video”. Ce dataset provient du site kaggle.com, et est fait par Salvatore Rastelli, Marco Sallustio et Marco Guarisco. Le dataset a été publié le 7 février 2023, avec les données provenant de 2 sources : Spotify, Youtube.

Ce jeu de données est composé de 20 717 individus, avec 28 features. Le tableau suivant contient chaque feature, type et son description : 

| *Feature*  | *Type* | *Description* |
| :-- | :-- | :------ |
| \# | entier | id |
| `Track` | string | Nom de la chanson tel qu'affiché sur Spotify. |
| `Artist` | string | Nom de l'artiste. |
| `Url_spotify` | string | Lien URL vers le profil Spotify de l'artiste. |
| `Album` | string | Album Spotify contenant la chanson. |
| `Album_type` | catégorielle | Indique si la chanson est sortie en tant que single, un album, ou autre. |
| `Uri` | string | Lien Spotify utilisé pour identifier précisément la chanson via l’API Spotify. |
| `Danceability` | float | Score (0 à 1\) indiquant à quel point la chanson est adaptée à la danse (0 \= peu adaptée, 1 \= très adaptée). |
| `Energy` | float | Mesure (0 à 1\) de l'intensité et de l'activité du morceau. Plus la valeur est élevée, plus le morceau est énergique et dynamique. |
| `Key` | catégorielle | Tonalité de la chanson représentée par un chiffre (0 \= Do, 1 \= Do/Ré, 2 \= Ré, etc.). Une valeur de \-1 indique une tonalité non détectée. |
| `Loudness` | float | Volume moyen de la chanson en décibels (dB), généralement entre \-60 et 0 dB. |
| `Speechiness` | float | Indique (0 à 1\) la présence de paroles parlées (0 \= essentiellement musicale, \>0.66 \= essentiellement parlée, entre 0.33 et 0.66 \= mixte). |
| `Acousticness` | float | Probabilité (0 à 1\) que le morceau soit acoustique (1 \= forte certitude d’un morceau acoustique). |
| `Instrumentalness` | float | Probabilité (0 à 1\) que le morceau soit instrumental (sans voix). Plus la valeur est élevée, plus la chanson est probablement instrumentale. |
| `Liveness` | float | Probabilité (0 à 1\) que le morceau ait été enregistré en direct (live). Valeurs \> 0.8 indiquent probablement une performance live. |
| `Valence` | float | Score (0 à 1\) représentant l’émotion positive transmise par la chanson (0 \= négatif/triste, 1 \= positif/joyeux). |
| `Tempo` | float | Tempo moyen de la chanson en battements par minute (BPM). |
| `Duration_ms` | float | Durée totale du morceau en millisecondes. |
| `Stream` | entier | Nombre total d’écoutes de la chanson sur Spotify. |
| `Url_youtube` | string | Lien vers la vidéo de la chanson sur YouTube, si disponible. |
| `Title` | string | Titre de la vidéo YouTube associée. |
| `Channel` | string | Nom de la chaîne YouTube qui a publié la vidéo. |
| `Views` | entier | Nombre de vues sur YouTube. |
| `Likes` | entier | Nombre de "J’aime" sur YouTube. |
| `Comments` | entier | Nombre de commentaires sur la vidéo YouTube. |
| `Description` | string | Description de la vidéo sur YouTube. |
| `Licensed` | catégorielle | Indique si la vidéo contient du contenu sous licence officielle revendiquée par un partenaire YouTube. |
| `official_video` | catégorielle | Valeur booléenne (Vrai/Faux) indiquant si la vidéo YouTube est la vidéo officielle de la chanson. |

Le dataset utilisé est complet et ne devrait pas nécessiter de traitement de données particulier avant son utilisation. Cependant, pour l’analyse de données dans le cadre de notre projet, certaines features ne sont pas nécessaires, notamment : 

* `Url_spotify`
* `Uri`  
* `Url_youtube`  
* `Description`

# Chargement des Librairies utilisées

Dans le cadre de ce projet, nous avons utilisé plusieurs bibliothèques, afin d'analyser, traiter et visualiser les données. Les bibliothèques utilisées sont : *ggplot2, scales, readr, dplyr, magrittr, tidyr, boot, forcats* et *fmsb*.

```{r libraries, echo=TRUE, warning=FALSE}
library(ggplot2)
library(scales)
library(readr)
library(dplyr)
library(magrittr)
library(tidyr)
library(boot)
library(forcats)
library(fmsb)
```

# Chargement du dataset

Le dataset utilisé se trouve dans le repertoire "data" et le fichier est nommé "Spotify_Youtube.csv". Il comporte toutes les données utilisés durant le projet.

```{r dataset, echo=TRUE, message=FALSE, warning=FALSE}
dataset <- read_csv("data/Spotify_Youtube.csv")
## Define theme colors to use for graphs
theme <- "#63a0e1"
darktheme <- "#2e7bcf"
```

# Analyse detaillée du dataset

L'analyse du dataset est separée en 3 grandes parties : **_Exploration_**, **_Impact sur le succès_** et **_Clustering_**.

- la première partie détaillera les comportements des features afin de trouver des corrélations entre elles et de comprendre la distribution des différentes caractéristiques
- la deuxième partie se concentrera sur la recherche des points clés pouvant impacter le succès d'une musique de manière significative
- dans la dernière partie, nous tenterons de regrouper différentes musiques à l'aide d'algorithmes de clustering

---

## Exploration

Dans cette partie, nous allons chercher des tendances dans les différentes features du dataset et trouver des corrélations entre elles. En d'autres termes, nous allons trouver quelles caractéristiques sont les plus courantes pour les chansons que nous traitons dans le cadre de notre étude. Ces résultats nous permettront peut-être de dégager des tendances, aussi bien au sein de notre dataset que sur les plateformes d'écoute (Spotify et Youtube), qui permettront de mieux comprendre les résultats des parties suivantes.

### Question 1 : Quelle est la répartition des types d'album dans le dataset ? 

L'objectif est de visualiser la fréquence des chansons issues d'albums par rapport aux singles.

**Hypothèses**

Nous pensons, que le nombre des singles doit être plus important que celui d'albums. En effet, depuis 2016, le nombre d'albums sorties en en déclin, tandis que le nomrbe des "EPs" et des singles est en augmentation.

**Traitement des données**

Avant de pouvoir visualiser cette répartition, il faut s'assurer que le dataset ne comporte pas des types incohérents, tel que "SinGLES" et "Abums".

```{r message=FALSE, warning=FALSE}
unique(dataset$Album_type)
```

D'après l'affichage ci-dessus, il n'y pas de valeurs incohérentes. Nous pouvons également voir que le dataset comporte 3 types d'albums : album, single et compilation. Le type compilation, correspond à un playlist créée par un utilisateur, qui comporte plusieurs chansons de différents artistes. 

**Visualisation**

Afin d'analyser la répartition des types d'albums, nous avons preferé utiliser un barplot, qui correspond bien à notre besoin.

Affichage du graphique 1 : 

```{r message=FALSE, warning=FALSE}
ggplot(dataset, aes(y = Album_type, fill = Album_type)) +
  geom_histogram(stat = "count") +
  labs(title = "Graphique 1 : Repartition des types d'Album", x = "Frequence", y = "Type d'Album") +
  theme_minimal()
```

**Observations diverses**

D'après le graphique 1, nous pouvons constater que la présence des albums est plus importante que celle des singles et des compilations. Cela peut être à cause du fait que les EPs sont considérés comme des Albums, car ils sont composés de 2-4 chansons. Cette séparation aurait été utile, car elle aurait permis de voir si notre dataset suit la tendance actuelle ou pas. Sans cette séparation, nous pouvons dire que le dataset ne suit pas la tendance actuelle.



### Question 2 : Quelle est la distribution des émotions (valence) des chansons ?

**Hypothèse :**

On souhaite savoir si les morceaux sont globalement joyeux ou tristes. On peut imaginer que certains types de musique sont plus présents sur une plateforme que sur l'autre, par exemple plus de musiques joyeuses sur Youtube et plus de musiques tristes sur Spotify.

**Traitement des données**

On filtre les valeurs de valence pour que la valence soit toujours comprise entre 0 et 1 et on sépare les musiques selon si elles sont présentes sur Spotify ou Youtube.

```{r message=FALSE, warning=FALSE}
spotify_dataset <- dataset %>%
  filter(Valence >= 0 & Valence <= 1 & !is.na(Stream)) %>%
  select(Valence) %>%
  na.omit()
youtube_dataset <- dataset %>%
  filter(Valence >= 0 & Valence <= 1 & !is.na(Views)) %>%
  select(Valence) %>%
  na.omit()
```

**Visualisations :**

```{r message=FALSE, warning=FALSE}
# Création de l'histogramme avec courbe de densité
spotify_dataset %>% ggplot(aes(x = Valence)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = theme, color = "white", alpha = 0.7) +
  geom_density(color = darktheme, size = 1) +
  labs(
    title = "Distribution des émotions (valence) des chansons sur Spotify",
    x = "Valence (0 = triste, 1 = joyeux)",
    y = "Densité"
  ) +
  theme_minimal()
youtube_dataset %>% ggplot(aes(x = Valence)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = theme, color = "white", alpha = 0.7) +
  geom_density(color = darktheme, size = 1) +
  labs(
    title = "Distribution des émotions (valence) des chansons sur Youtube",
    x = "Valence (0 = triste, 1 = joyeux)",
    y = "Densité"
  ) +
  theme_minimal()
```

Les résultats de ces premiers graphiques montrent que les musiques présentes sur les deux plateformes sont plus joyeuses que tristes. Cela dit, il pourrait être intéressant de connaitre :

- le pourcentage de musiques plutôt joyeuse ($Valence > 0,5$)
- la valence moyenne des musiques du dataset
- la répartition de la valence des musiques présentes exclusivement sur l'une des deux plateformes (puisqu'on a $19673$ musiques qui sont communes aux deux plateformes)

**Déterminons le pourcentage de musiques plutôt joyeuses dans le dataset** 

```{r message=FALSE, warning=FALSE}
dataset %>%
  filter(Valence > 0.5) %>%
  nrow() / dataset %>% nrow()
```

Les musiques sont donc de manière générale plus joyeuses que tristes dans notre dataset.

**Déterminons la valence moyenne des musiques**

```{r message=FALSE, warning=FALSE}
dataset$Valence %>% mean(na.rm = TRUE)
```

**Trouvons la répartition de la valence des musiques présentes uniquement sur l'une des deux platformes**

```{r message=FALSE, warning=FALSE}
spotify_only_dataset <- dataset %>%
  filter(Valence >= 0 & Valence <= 1 & is.na(Views)) %>%
  select(Valence) %>%
  na.omit()
youtube_only_dataset <- dataset %>%
  filter(Valence >= 0 & Valence <= 1 & is.na(Stream)) %>%
  select(Valence) %>%
  na.omit()
spotify_only_dataset %>% ggplot(aes(x = Valence)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = theme, color = "white", alpha = 0.7) +
  geom_density(color = darktheme, size = 1) +
  labs(
    title = "Distribution de la valence des chansons présentes exclusivement sur Spotify",
    x = "Valence (0 = triste, 1 = joyeux)",
    y = "Densité"
  ) +
  theme_minimal()
youtube_only_dataset %>% ggplot(aes(x = Valence)) +
  geom_histogram(aes(y = ..density..), bins = 30, fill = theme, color = "white", alpha = 0.7) +
  geom_density(color = darktheme, size = 1) +
  labs(
    title = "Distribution de la valence des chansons présentes exclusivement sur Youtube",
    x = "Valence (0 = triste, 1 = joyeux)",
    y = "Densité"
  ) +
  theme_minimal()
```

Pour rappel, ces graphiques se basent sur peu de données, à savoir sur $469$ valeurs pour Spotify et $576$ valeurs pour Youtube.

```{r message=FALSE, warning=FALSE}
nrow(spotify_only_dataset)
nrow(youtube_only_dataset)
```

Il apparait cependant que les musiques présentes uniquement sur Spotify ont tendance à avoir une valence répartie autour de $0,7$ : ce sont donc des musiques relativement joyeuses; là où les musiques présentes exclusivement sur Youtube ont une valence mieux répartie, incluant ainsi plus de musiques plus joyeuses et plus de musiques plus tristes que sur Spotify.



### Question 3 : Quelle est la distribution des durées des morceaux ? 

Nous voulons observer si les morceaux présents dans le dataset suivent une longueur standard.

**Hypothèses**

D'après une étude en 2019, faite par le média américain Quartz, la durée moyenne d'une chanson est de 3min 30s.

**Traitement des données**

Avant de faire des visualisations, nous devons nous assurer qu'il n'y a pas de valeurs `null` dans la colonne `Duration_ms`. Après cela, nous allons changer l'unité de durée, passant de ms en minutes, afin de mieux interpréter les valeurs.

```{r message=FALSE, warning=FALSE}
dataset_question_5 <- dataset %>%
  filter(!is.na(Duration_ms)) %>%
  mutate(Duration_min = (Duration_ms / 1000) / 60)
```

**Visualisation**

Le premier graphe est un boxplot, afin de voir le nombre d'outliers présents dans le dataset.

Affichage du graphique 1 : 

```{r message=FALSE, warning=FALSE}
mean_duree <- mean(dataset_question_5$Duration_min)
ggplot(dataset_question_5, aes(x = "", y = Duration_min)) +
  geom_violin(fill = darktheme, color = "black") +
  geom_hline(yintercept = mean_duree, linetype = "dashed", color = "red", size = 1) +
  annotate("text", x = 1.2, y = mean_duree + 3.3, label = paste("Moyenne =", round(mean_duree, 2)), color = "red") +
  theme_minimal() +
  labs(
    title = "Graphique 1 : Distribution de la durée d'une chanson",
    x = "",
    y = "Durée d'une chanson (en minutes)"
  )
```

Sur ce graphe, nous pouvons voir que la durée moyenne d'une chanson est de 3min42, ce qui est très proche de notre hypothèse. Cependant, nous pouvons voir qu'il y a beaucoup d'outliers. Quelques-uns d'entre eux sont très loin de la durée moyenne, ce qui peut impacter la moyenne. Afin de mieux voir la répartition des valeurs, nous pouvons utiliser un histogramme. Dans cet histogramme, nous n'allons pas considérer les valeurs au-dessus de 10 minutes.

Affichage du graphique 2 : 

```{r message=FALSE, warning=FALSE}
dataset_question_5_plot2 <- dataset_question_5 %>% filter(Duration_min < 10)

ggplot(data = dataset_question_5_plot2, aes(x = Duration_min)) +
  geom_histogram(aes(y = ..density..), bins = 50, fill = darktheme, color = "#e9ecef", alpha = 0.9) +
  stat_function(
    fun = dnorm,
    args = list(mean = mean(dataset_question_5_plot2$Duration_min), sd = sd(dataset_question_5_plot2$Duration_min)),
    aes(color = "Densité theorique"),
    size = 1
  ) +
  geom_vline(aes(xintercept = mean(Duration_min)), color = "red", linetype = "dashed", size = 0.5) +
  scale_x_continuous(breaks = seq(0, 20, 1)) +
  ggtitle("Graphique 2 : Repartition de musiques en fonction de la durée") +
  labs(x = "Durée (en minutes)", y = "Fréquence") +
  scale_color_manual(
    name = "Légende",
    values = c("Densité theorique" = "red")
  )
```

Maintenant qu'on a vu la repartition, il serait intéressant de voir si les chansons d'une durée entre 3 à 4 minutes ont une tonalité différente de celle des outliers.

Affichage du graphique 3 : 

```{r message=FALSE, warning=FALSE}
dataset_question5_plot3 <- dataset_question_5 %>%
  filter(Duration_min <= 4) %>%
  filter(Duration_min >= 3) %>%
  count(Key) %>%
  arrange(n)

dataset_question5_plot3$Key <- factor(dataset_question5_plot3$Key, levels = dataset_question5_plot3$Key)

dataset_question5_plot3$Key <- fct_recode(dataset_question5_plot3$Key,
  "Do" = "0",
  "Do / Ré" = "1",
  "Ré" = "2",
  "Ré / Mi" = "3",
  "Mi" = "4",
  "Fa" = "5",
  "Fa / Sol" = "6",
  "Sol" = "7",
  "Sol / La" = "8",
  "La" = "9",
  "La / Si" = "10",
  "Si" = "11"
)

ggplot(dataset_question5_plot3, aes(x = Key, y = n, fill = Key)) +
  geom_bar(width = 0.9, stat = "identity") +
  coord_polar(theta = "y") +
  ylim(c(0, 2000)) +
  ggtitle("Graphique 3 : Repartition de musiques d'une durée entre 3 à 4 minutes en fonction de la tonalité") +
  labs(x = "Tonalité", y = "Frequence", fill = "Tonalité")
```

Affichage du graphique 4 : 

```{r message=FALSE, warning=FALSE}
dataset_question5_plot4 <- dataset_question_5 %>%
  filter(Duration_min >= 10) %>%
  count(Key) %>%
  arrange(n)

dataset_question5_plot4$Key <- factor(dataset_question5_plot4$Key, levels = dataset_question5_plot4$Key)

dataset_question5_plot4$Key <- fct_recode(dataset_question5_plot4$Key,
  "Do" = "0",
  "Do / Ré" = "1",
  "Ré" = "2",
  "Ré / Mi" = "3",
  "Mi" = "4",
  "Fa" = "5",
  "Fa / Sol" = "6",
  "Sol" = "7",
  "Sol / La" = "8",
  "La" = "9",
  "La / Si" = "10",
  "Si" = "11"
)

ggplot(dataset_question5_plot4, aes(x = Key, y = n, fill = Key)) +
  geom_bar(width = 0.9, stat = "identity") +
  coord_polar(theta = "y") +
  ylim(c(0, 40)) +
  ggtitle("Graphique 4 : Repartition de musiques d'une durée superieur de 20 minutes en fonction de la tonalité") +
  labs(x = "Tonalité", y = "Frequence", fill = "Tonalité")
```

**Observations diverses**

D'après les 4 visualisations ci-dessous, nous avons vu que le dataset respecte bien la durée moyenne d'une chanson, malgré la présence de certains outliers. Pour aller plus loin, nous avons regardé la tonalité des chansons d'une durée moyenne, comparée à la tonalité des chansons d'une durée superieure à 10 minutes. 

Pour le graphique 3, les tonalités les plus presentes sont Do/Ré, Sol et Do. Pour le graphique 4, les tonalités les plus présentes sont Sol et Mi. Ce qui aurait été pertinent dans l'analyse, c'est d'avoir également une séparation entre les gammes majeures et mineures.  



### Question 4 : Quelle est la tonalité la plus fréquente dans les chansons du dataset ?

**Hypothèse**

Certaines tonalités sont peut être plus présentes que d'autres dans le dataset.

**Traitement des données**

Afin de pouvoir utiliser les données correctement et d'afficher les résultats de manière lisible, on va transformer les codes des différentes tonalités en leur valeur (ex. 0 = Do). Par la même occasion, on crée une catégorie pour les musiques dont la tonalité n'a pu être déterminée. On retire également les colonnes inutiles.

```{r message=FALSE, warning=FALSE}
keys <- dataset %>%
  select(Key, Views, Stream, Likes, Comments) %>%
  mutate(Key = replace_na(Key, 12))
note_labels <- c(
  "Do",
  "Do♯/Ré♭",
  "Ré",
  "Ré♯/Mi♭",
  "Mi",
  "Fa",
  "Fa♯/Sol♭",
  "Sol",
  "Sol♯/La♭",
  "La",
  "La♯/Si♭",
  "Si",
  "Tonalité inconnue"
)
keys$Key <- factor(keys$Key, levels = 0:12, labels = note_labels)
keys_only <- keys %>% select(Key)
```

**Visualisations**

Nous allons compter le nombre de musiques pour chaque tonalité, et afficher les résultats à l'aide d'un barchart.

```{r message=FALSE, warning=FALSE}
keys_only %>% ggplot(aes(x = Key)) +
  geom_bar(fill = theme, color = "white", width = 1) +
  labs(
    title = "Distribution des tonalités",
    x = "Tonalité",
    y = "Nombre de musiques"
  ) +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.4, hjust = 0.9),
    plot.title = element_text(size = 12)
  )
```

On constate que certaines tonalités sont légèrement plus présentes que les autres sur les plateformes Youtube and Spotify, comme le Do, Sol, Do♯/Ré♭, Ré et La.

On remarque également qu'il y a nettement moins de musiques avec la tonalité Ré♯/Mi♭. On va tenter de voir s'il existe des corrélations entre le succès d'une musique et sa tonalité, ce qui pourrait expliquer le faible nombre de musiques en Ré♯/Mi♭.

```{r message=FALSE, warning=FALSE, fig.height=3}
keys %>%
  filter(Key != note_labels[13]) %>%
  group_by(Key) %>%
  summarise(
    Streams = mean(Stream, na.rm = TRUE), Likes = mean(Likes, na.rm = TRUE),
    Comments = mean(Comments, na.rm = TRUE), Views = mean(Views, na.rm = TRUE)
  ) %>%
  mutate(across(
    where(is.numeric),
    ~ (. - min(., na.rm = TRUE)) / (max(., na.rm = TRUE) - min(., na.rm = TRUE))
  )) %>%
  pivot_longer(
    cols = c(Streams, Likes, Comments, Views), names_to = "Stat", values_to = "Value"
  ) %>%
  ggplot(aes(x = Key, y = Stat, fill = Value)) +
  geom_tile() +
  scale_fill_viridis_c(option = "inferno") +
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle = 90, vjust = 0.4, hjust = 0.9),
    plot.title = element_text(size = 12)
  ) +
  ggtitle("Succès moyen de la musique selon la tonalité") +
  labs(fill = "Succès\n(normalisé)")
```

Afin de mieux comprendre l'échelle utilisée dans ce graphique, on a calculé la différence entre la valeur la plus foncée et la valeur la plus claire :

| Critère | Views | Streams | Likes | Comments |
| - | - | - | - | - | - |
| Différence maximale | 35803828 | 223427.8 | 19711.53 | 28328929 |
| Part de la valeur maximale | 0.23 | 0.29 | 0.49 | 0.26 |

Les différences présentes dans ce graphique sont donc significatives, et on peut constater que les musiques en Si, Fa♯/Sol♭ sont les musiques avec le plus gros succès en moyenne sur Youtube là où les musiques en Do♯/Ré♭ sont les musiques qui ont le plus gros succès en moyenne sur Spotify.

La réponse à la question soulevée par le graphique précédent, à savoir *est-ce que les musiques en Ré♯/Mi♭ sont les moins présentes des plateformes de streaming à cause de leur manque de popularité*, n'est pas tout à fait claire.

En effet, les musiques en La et Sol ont des performances moyennes inférieures mais sont plus nombreuses sur Youtube et Spotify.



### Question 5 : Est-ce qu'une tonalité a un effet sur le type de chanson ? 

Dans cette question, nous allons examiner les differentes caractéristiques des musiques pour chaque tonalité. Le but est de voir s'il existe une variation des différentes caractéristiques en fonction de la tonalité globale de la chanson.

**Hypothèses**

Avant de faire des visualisations, nous pouvons supposer que la tonalité a un effet sur certaines caractéristiques, pas toutes. Par exemple, les tonalités majeures sont plus chaleureuses et festives, tandis que les tonalités mineures donnent un effet plutôt nostaligique. Ainsi, nous pouvons supposer que les chansons dans les tonalités majeures vont avoir les features, tel que "danceability" et "energy" plus importantes que les chansons écrites dans des tonalités mineures.

**Traitement des données**

Le dataset, tel qu'il est actuellement, n'est pas adapté à faire une seule visualisation représentant toutes les caractéristiques en fonction des tonalités. Afin de pouvoir visualiser les carecteristiques des chansons, nous devions crée des data frames, afin de les visualiser sous des radar charts. 

```{r message=FALSE, warning=FALSE}
note_labels <- c(
  "Do",
  "Do♯/Ré b",
  "Ré",
  "Ré♯/Mi b",
  "Mi",
  "Fa",
  "Fa♯/Sol b",
  "Sol",
  "Sol♯/La b",
  "La",
  "La♯/Si b",
  "Si",
  "Tonalité inconnue"
)

max_danceability <- dataset[which.max(dataset$Danceability), ]
max_energy <- dataset[which.max(dataset$Energy), ]
max_speechiness <- dataset[which.max(dataset$Speechiness), ]
max_acousticness <- dataset[which.max(dataset$Acousticness), ]
max_instrumentalness <- dataset[which.max(dataset$Instrumentalness), ]
max_liveness <- dataset[which.max(dataset$Liveness), ]
max_valence <- dataset[which.max(dataset$Valence), ]
max_tempo <- dataset[which.max(dataset$Tempo), ]
max_loudness <- dataset[which.max(dataset$Loudness), ]

graphe_max_danceability <- data.frame(
  valence = max_danceability[1, 16],
  liveness = max_danceability[1, 15],
  instrumentalness = max_danceability[1, 14],
  acousticness = max_danceability[1, 13],
  speechiness = max_danceability[1, 12],
  energy = max_danceability[1, 9],
  danceability = max_danceability[1, 8],
  tempo = (max_danceability[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_danceability[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_loudness <- data.frame(
  valence = max_loudness[1, 16],
  liveness = max_loudness[1, 15],
  instrumentalness = max_loudness[1, 14],
  acousticness = max_loudness[1, 13],
  speechiness = max_loudness[1, 12],
  energy = max_loudness[1, 9],
  danceability = max_loudness[1, 8],
  tempo = (max_loudness[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_loudness[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_tempo <- data.frame(
  valence = max_tempo[1, 16],
  liveness = max_tempo[1, 15],
  instrumentalness = max_tempo[1, 14],
  acousticness = max_tempo[1, 13],
  speechiness = max_tempo[1, 12],
  energy = max_tempo[1, 9],
  danceability = max_tempo[1, 8],
  tempo = (max_tempo[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_tempo[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_energy <- data.frame(
  valence = max_energy[1, 16],
  liveness = max_energy[1, 15],
  instrumentalness = max_energy[1, 14],
  acousticness = max_energy[1, 13],
  speechiness = max_energy[1, 12],
  energy = max_energy[1, 9],
  danceability = max_energy[1, 8],
  tempo = (max_energy[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_energy[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_speechiness <- data.frame(
  valence = max_speechiness[1, 16],
  liveness = max_speechiness[1, 15],
  instrumentalness = max_speechiness[1, 14],
  acousticness = max_speechiness[1, 13],
  speechiness = max_speechiness[1, 12],
  energy = max_speechiness[1, 9],
  danceability = max_speechiness[1, 8],
  tempo = (max_speechiness[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_speechiness[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_acousticness <- data.frame(
  valence = max_acousticness[1, 16],
  liveness = max_acousticness[1, 15],
  instrumentalness = max_acousticness[1, 14],
  acousticness = max_acousticness[1, 13],
  speechiness = max_acousticness[1, 12],
  energy = max_acousticness[1, 9],
  danceability = max_acousticness[1, 8],
  tempo = (max_acousticness[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_acousticness[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_instrumentalness <- data.frame(
  valence = max_instrumentalness[1, 16],
  liveness = max_instrumentalness[1, 15],
  instrumentalness = max_instrumentalness[1, 14],
  acousticness = max_instrumentalness[1, 13],
  speechiness = max_instrumentalness[1, 12],
  energy = max_instrumentalness[1, 9],
  danceability = max_instrumentalness[1, 8],
  tempo = (max_instrumentalness[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_instrumentalness[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_liveness <- data.frame(
  valence = max_liveness[1, 16],
  liveness = max_liveness[1, 15],
  instrumentalness = max_liveness[1, 14],
  acousticness = max_liveness[1, 13],
  speechiness = max_liveness[1, 12],
  energy = max_liveness[1, 9],
  danceability = max_liveness[1, 8],
  tempo = (max_liveness[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_liveness[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_max_valence <- data.frame(
  valence = max_valence[1, 16],
  liveness = max_valence[1, 15],
  instrumentalness = max_valence[1, 14],
  acousticness = max_valence[1, 13],
  speechiness = max_valence[1, 12],
  energy = max_valence[1, 9],
  danceability = max_valence[1, 8],
  tempo = (max_valence[1, 17] - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (max_valence[1, 11] - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)

graphe_mean <- data.frame(
  valence = mean(dataset$Valence, na.rm = TRUE),
  liveness = mean(dataset$Liveness, na.rm = TRUE),
  instrumentalness = mean(dataset$Instrumentalness, na.rm = TRUE),
  acousticness = mean(dataset$Acousticness, na.rm = TRUE),
  speechiness = mean(dataset$Speechiness, na.rm = TRUE),
  energy = mean(dataset$Energy, na.rm = TRUE),
  danceability = mean(dataset$Danceability, na.rm = TRUE),
  tempo = (mean(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)) / (max(dataset$Tempo, na.rm = TRUE) - min(dataset$Tempo, na.rm = TRUE)),
  loudness = (mean(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE)) / (max(dataset$Loudness, na.rm = TRUE) - min(dataset$Loudness, na.rm = TRUE))
)
max_min <- data.frame(
  Valence = c(1, 0), Liveness = c(1, 0), Instrumentalness = c(1, 0),
  Acousticness = c(1, 0), Speechiness = c(1, 0), Energy = c(1, 0),
  Danceability = c(1, 0), Tempo = c(1, 0), Loudness = c(1, 0)
)
max_min_bis <- data.frame(
  valence = c(1, 0), liveness = c(1, 0), instrumentalness = c(1, 0),
  acousticness = c(1, 0), speechiness = c(1, 0), energy = c(1, 0),
  danceability = c(1, 0), tempo = c(1, 0), loudness = c(1, 0)
)

rownames(max_min) <- c("Max", "Min")
graphe_mean <- rbind(max_min_bis, graphe_mean)
graphe_max_danceability <- rbind(max_min, graphe_max_danceability)
graphe_max_energy <- rbind(max_min, graphe_max_energy)
graphe_max_speechiness <- rbind(max_min, graphe_max_speechiness)
graphe_max_instrumentalness <- rbind(max_min, graphe_max_instrumentalness)
graphe_max_liveness <- rbind(max_min, graphe_max_liveness)
graphe_max_valence <- rbind(max_min, graphe_max_valence)
graphe_max_acousticness <- rbind(max_min, graphe_max_acousticness)
graphe_max_tempo <- rbind(max_min, graphe_max_tempo)
graphe_max_loudness <- rbind(max_min, graphe_max_loudness)
```

**Visualisation**

Apres avoir analysé les caracteristiques moyennes des chansons en fonction de chaque tonalité, nous nous avions rendu compte  du fait, que les caracteristiques sont d'une meme moyenne pour chaque tonalité. Le radar chart suivant montre les caracteristiques moyennes d'une chanson. En effet, la tonalité ne joue pas sur les caracteristiques d'une chanson.

Affichage du graphique 1 : 

```{r message=FALSE, warning=FALSE}
create_beautiful_radarchart <- function(data, color = "#00AFBB",
                                        vlabels = colnames(data), vlcex = 0.7,
                                        caxislabels = NULL, title = NULL,
                                        subtitle = NULL, cex.main = 1, ...) {
  radarchart(
    data,
    axistype = 1,
    pcol = color, pfcol = scales::alpha(color, 0.5), plwd = 2,
    cglcol = "grey", cglty = 1, cglwd = 0.8,
    axislabcol = "grey",
    vlcex = vlcex, vlabels = vlabels,
    caxislabels = caxislabels, title = title,
    cex.main = cex.main,
    ...
  )
  if (!is.null(subtitle)) {
    mtext(subtitle, side = 1, line = 2, cex = 0.8)
  }
}

create_beautiful_radarchart(
  data = graphe_mean,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#FC4E07",
  title = "Graphique 1 : Les caracteristiques moyennes d'une chanson"
)
```

Afin d'aller plus loin, nous avons fait des radarcharts des différentes chansons, qui ont une caractéristique au niveau maximum.

Affichage du graphique 2 : 

```{r message=FALSE, warning=FALSE}
# Préparer une grille 3x3 pour les 9 graphiques
par(mfrow = c(3, 3), mar = c(3, 3, 3, 3))

create_beautiful_radarchart(
  data = graphe_max_danceability,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#00AFBB",
  title = paste("La chanson : ", substr(max_danceability[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_danceability[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_energy,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#E7B800",
  title = paste("La chanson : ", substr(max_energy[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_energy[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_speechiness,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#FF61C3",
  title = paste("La chanson : ", substr(max_speechiness[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_speechiness[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_acousticness,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#7CAE00",
  title = paste("La chanson : ", substr(max_acousticness[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_acousticness[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_instrumentalness,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#619CFF",
  title = paste("La chanson : ", substr(max_instrumentalness[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_instrumentalness[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_liveness,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#00C19F",
  title = paste("La chanson : ", substr(max_liveness[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_liveness[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_valence,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#C77CFF",
  title = paste("La chanson : ", substr(max_valence[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_valence[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_tempo,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#F8766D",
  title = paste("La chanson : ", substr(max_tempo[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_tempo[1, 10][[1]] + 1]]),
  cex.main = 0.7
)

create_beautiful_radarchart(
  data = graphe_max_loudness,
  caxislabels = c(0, 2.5, 5, 7.5, 10),
  color = "#FFB000",
  title = paste("La chanson : ", substr(max_loudness[1, 4], 1, 17), "..."),
  subtitle = paste("Tonalité : ", note_labels[[max_loudness[1, 10][[1]] + 1]]),
  cex.main = 0.7
)
```

**Observations diverses**

D'après ces radarcharts, nous avons pu regarder les différentes "formes" des chansons. Certains de ces chansons ont des valeurs correctes, tel que "Give it to me", qui a la danceability maximale. Cependant, le morceau "Clean White Noises" a un "instrumentalness" et une "acousticness" très hauts. Cela est assez surprenant, sachant que les bruits blancs n'ont pas d'instruments acoustiques... De plus, "Teil 7", qui est un récit de sherlock en allemand a un niveau de "speechiness" impressionnant. 

Cette analyse nous a permis de comprendre que le dataset ne contient pas que des chansons. De plus, cela permet de nous questionner sur comment est ce que les données sont calculés.



### Question 6 : Y a-t-il une corrélation entre la “danceability” et le tempo ?

**Hypothèse **

La *danceability* est un score qui indique à quel point une chanson est adaptée à la danse. Il est donc logique de penser qu'il existe une certaine corrélation entre le tempo et la *danceability*. En effet, un morceau avec un tempo rapide pourrait être plus dansant qu'un morceau avec un tempo lent.

**Traitement **

Pour réaliser cela nous allons utiliser un scatter plot ainsi qu'une courbe de tendance pour permettre d'identifier plus facilement si une tendance existe.
Nous allons également supprimer les valeurs anormales, c'est-à-dire les morceaux avec un tempo inférieur à 20 BPM ou supérieur à 250 BPM. En effet, ces morceaux sont très rares et pourraient fausser notre analyse.

```{r message=FALSE, warning=FALSE}
dataset %>%
  filter((Tempo > 20 & Tempo < 250)) %>%
  ggplot(aes(x = Tempo, y = Danceability)) +
  geom_hex(bins = 50) +
  scale_fill_viridis_c() +
  geom_smooth(method = "gam", se = FALSE, size = 1.5, color = "#FDE725") +
  labs(title = "Corrélation entre le tempo et la danceability", x = "Tempo (BPM)", y = "Danceability") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12),
    panel.grid.major = element_line(color = "gray80"),
    panel.grid.minor = element_blank(),
  )
```

**Observations **

D'après le graphique, on constate qu'il y a une légère corrélation entre le tempo et la *danceability*. En effet, plus le tempo est élevé, plus la *danceability* augmente, jusqu'à un certain point. Au-delà de 120 BPM, la *danceability* semble se stabiliser voir même diminuer. Cela peut s'expliquer par le fait que les morceaux très rapides peuvent devenir trop complexes pour être dansés facilement. Ou encore que l'ensemble des données est très concentré vers les 100 BPM, ce qui fausse la perception de la tendance.

```{r message=FALSE, warning=FALSE}
# affichage de la repartition du tempo
dataset %>% ggplot(aes(x = Tempo)) +
  geom_histogram(binwidth = 5, fill = "steelblue", color = "black", alpha = 0.7) +
  labs(title = "Répartition du tempo", x = "Tempo (BPM)", y = "Nombre de morceaux") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5, size = 18, face = "bold"),
    axis.title = element_text(size = 14),
    axis.text = element_text(size = 12)
  )
```

En effet on remarque que la forme est similaire à une gaussienne, avec un maximum vers 100 BPM. Cela peut expliquer la tendance observée précédemment. Il n'y aurait donc pas ou très peu de corrélation entre le tempo et la *danceability*.

### Conclusion de la partie exploration

Nous avons vu dans cette première partie que :

- contrairement à la tendance, les musiques de notre dataset sont plus tirées d'albums que de singles
- les musiques sont globalement joyeuses et que le niveau de joyeuseté est plus réparti sur Youtube que sur Spotify
- les musiques ont une durée moyenne proche des constats d'une étude américaine : 3m30. Cependant il y a certains morceaux qui sont beaucoup plus longs
- les tonalités sont toutes bien présentes dans notre dataset, à l'exception du Re/Mi qui est beaucoup plus rare. Ceci n'est pas corrélé à un manque de succès de tels morceaux
- la tonalité ne joue pas sur les caractéristiques d'une chanson
- il y a peu de corrélation entre la côté dansant d'une chanson et son tempo
- notre dataset contient autre chose que des musiques : bruit blanc, livre audio, etc

---

## Impact sur le succès

Dans cette partie, nous allons tenter de déterminer quelles caractéristiques d'une chanson contribuent à son succès.

### Question 7 : Les chansons live ont-elles tendance à avoir plus de vue sur Youtube que Spotify ?

**Hypothèse **

On peut imaginer que les chansons live sont plus populaires sur Youtube que sur Spotify, car Youtube est une plateforme de vidéo et de contenu visuel. De plus, les concerts et les performances live sont souvent partagés sur Youtube, ce qui pourrait expliquer une tendance à avoir plus de vues sur cette plateforme.

**Traitement des données **

Nous allons créer deux boxplot pour comparer le nombre de vues sur Youtube et Spotify pour les chansons live et non-live (studio).
Nous allons également créer une nouvelle variable pour différencier les morceaux live et studio à l'aide de la feature *Liveness*. En effet, cette feature indique si le morceau a été enregistré en live ou non. Nous allons donc créer une nouvelle variable *is_live* qui prendra la valeur "Live" si la valeur de *Liveness* est supérieure à 0.8, et "Studio" sinon.
L'affichage des boxplots se fera suivant une échelle logarithmique, afin de mieux visualiser les différences entre les deux plateformes.

```{r message=FALSE, warning=FALSE}
# Afficher le nombre de musiques live
live_music <- dataset %>%
  filter(Liveness > 0.8) %>%
  select(contains("Stream"), contains("Views"))
print(paste("Nombre de musiques live :", nrow(live_music)))
```

Nous remarquons que le nombre de musique live n'est que de 385, soit environ 2% du dataset. Les résultats pourraient donc être biaisés par le faible nombre de musiques live.

**Visualisations**

```{r message=FALSE, warning=FALSE}
# Crée une variable pour différencier les morceaux live et studio
live_dataset <- dataset %>%
  filter(!is.na(Liveness)) %>%
  mutate(is_live = ifelse(Liveness > 0.8, "Live", "Studio"))

# Crée une fonction pour créer les boxplots
plot_boxplot <- function(data, xvar, yvar, xlab, ylab, title, subtitle) {
  ggplot(data, aes_string(x = xvar, y = yvar, fill = xvar)) +
    geom_boxplot(outlier.shape = NA, size = 0.7) +
    scale_y_log10(labels = scales::comma) +
    labs(
      title = title,
      subtitle = subtitle,
      x = xlab,
      y = ylab,
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 18, hjust = 0.5, face = "bold"),
      plot.subtitle = element_text(size = 13, hjust = 0.5),
      axis.title = element_text(size = 14),
      axis.text = element_text(size = 12),
    ) +
    guides(fill = "none")
}

# Appel de la fonction pour créer les boxplots
plot_streams <- plot_boxplot(
  live_dataset, "is_live", "Stream", "Type de chanson", "Nombre d'écoutes (log)",
  "Comparaison des écoutes Spotify", "Entre chansons Live et Studio"
)

plot_views <- plot_boxplot(
  live_dataset, "is_live", "Views", "Type de chanson", "Nombre de vues (log)",
  "Comparaison des vues YouTube", "Entre chansons Live et Studio"
)

plot_streams
plot_views
```

**Observations**

D'après les boxplots, on constate que les morceaux live ont tendance à avoir plus de vues sur Youtube que sur Spotify. En effet, les médianes des vues Youtubes sont très similaires, mais les morceaux live ont une plus grande amplitude de vues sur Youtube que sur Spotify.
Cela peut confirmer l'hypothèse selon laquelle les morceaux live sont plus populaires sur Youtube que sur Spotify. Cependant, il est important de noter que le nombre de morceaux live est très faible par rapport au nombre total de morceaux, ce qui peut fausser les résultats. De plus, il est possible que d'autres facteurs influencent le nombre de vues et d'écoutes, tels que la popularité de l'artiste ou la qualité de la vidéo.



### Question 8 : Les vidéos officielles ont-elles plus de vues que les autres ?

**Hypothèse**

Les vidéos officielles pourraient avoir plus de vues que les autres

**Traitement des données**

On ne garde "que" les $19549$ vidéos de Youtube.

```{r message=FALSE, warning=FALSE}
youtube_dataset <- dataset %>%
  filter(!is.na(Views)) %>%
  select(where(is.numeric), Views, official_video) %>%
  na.omit()
```

**Visualisations**

On affiche les vues selon si la vidéo est officielle ou non.

```{r message=FALSE, warning=FALSE}
ggplot(youtube_dataset, aes(y = Views, x = official_video)) +
  geom_boxplot() +
  scale_y_log10(labels = label_number(scale_cut = cut_short_scale())) +
  scale_x_discrete(labels = c("Non officielle", "Officielle")) +
  labs(x = "Type de vidéo", y = "Nombre de vues") +
  ggtitle("Graphique 1 : Répartition du nombre de vues selon si la vidéo est officielle")

ggplot(youtube_dataset, aes(Views, fill = official_video, color = official_video)) +
  geom_density(alpha = 0.1) +
  scale_x_log10(labels = label_number(scale_cut = cut_short_scale())) +
  scale_color_discrete(name = "Type de vidéo", labels = c("Non officielle", "Officielle")) +
  scale_fill_discrete(guide = "none") +
  ggtitle("Graphique 2 : Densité du nombre de vues selon si la vidéo est officielle") +
  labs(x = "Nombre de vues", y = "Densité") +
  theme(axis.text.y = element_blank())
```

Afin de bien comprendre ces graphiques, on calcule le nombre de vidéos officielles et non officielles :

| Vidéos officielles | Vidéos non officielles |
| - | - |
| 15260 | 4289 |

Les vidéos officielles font donc plus de vues que les vidéos non officielles. On peut noter cependant que nous avons plus de vidéos officielles que de vidéos non officielles dans le dataset. On peut supposer que les artistes connus publient tous leurs musiques dans des musiques "officielles" et que leurs republications se font supprimer par Youtube.

### Question 9 :  Quelles sont les variables qui influencent les performances sur Youtube et Spotify ?

**Hypothèse**

Certaines features, comme l'énergie ou le tempo sont peut être corrélées avec les performances. Pour rappel, les indicateurs de performance dépendent de la plateforme :

- nombre de vues, likes et commentaires pour Youtube
- nombre de streams pour Spotify

**Traitement des données**

Nous souhaitons réaliser une heatmap de la corrélation entre les features et les performances des musiques. Puisque la performance ne se mesure pas de la même façon sur les deux plateformes, nous allons faire deux heatmaps et donc séparer le dataset en deux : les musiques présentes sur Spotify et les musiques présentes sur Youtube. \
Afin de calculer correctement la corrélation entre les différentes features et les indices de performance, on enlève également toutes les musiques dont au moins une feature est absente de notre dataset.

```{r message=FALSE, warning=FALSE}
# Commençons par Spotify
spotify_dataset <- dataset %>%
  filter(!is.na(Stream)) %>% # On retire les musiques qui n'ont pas de nombre de streams
  select(where(is.numeric), -...1, -Likes, -Views, -Comments) %>% # On retire les colonnes inutiles
  na.omit()
# On retire la ligne si elle contient des valeurs non numériques
spotify_dataset %>%
  nrow() %>%
  print()
# On affiche le nombre de musiques présentes sur Spotify
# Faisons la même chose pour Youtube
youtube_dataset <- dataset %>%
  filter(!is.na(Views)) %>%
  select(where(is.numeric), -...1, -Stream) %>%
  na.omit()
youtube_dataset %>%
  nrow() %>%
  print()
```

On va donc visualiser les données de $20140$ musiques pour Spotify et $20099$ musiques pour Youtube.

**Visualisations**

Faisons d'abord une heatmap pour montrer la corrélation entre les différentes features et la performance des musiques sur Spotify :

```{r message=FALSE, warning=FALSE}
correlation <- spotify_dataset %>%
  cor(method = "pearson") %>% # Dressons une matrice de corrélation en utilisant les valeurs
  as.table() %>% # On transforme la matrice en un tableau contenant la ligne, la colonne et la valeur
  as.data.frame() %>% # On recupère le tableau dans un dataframe
  mutate(value = abs(Freq))
# On ne conserve que la valeur absolue de la corrélation
correlation %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_viridis_c(option = "inferno") +
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle = 90, vjust = 0.4, hjust = 0.9),
    plot.title = element_text(size = 12)
  ) +
  ggtitle("Corrélation entre les différentes features et les performances sur Spotify") +
  labs(fill = "Indice de\ncorrélation")
```

On constate déjà que la performance sur Spotify *(Stream)* est très peu corrélée avec les différentes features des musiques. On voit que la corrélation la plus élevée reste très faible (~15%) et concerne l'intensité sonore, l'acoustique et l'instrumentalité.

Afin d'y voir plus clair, nous allons réaliser un *BarPlot* des features pour afficher leur corrélation avec le nombre de streams :

```{r message=FALSE, warning=FALSE}
columns <- c("Stream", "Views", "Likes", "Comments")
correlation %>%
  filter(Var1 %in% columns & !Var2 %in% columns) %>%
  ggplot(aes(x = Var2, y = value, fill = Var1)) +
  geom_bar(position = "dodge", stat = "identity") +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.4, hjust = 0.9),
    plot.title = element_text(size = 12)
  ) +
  labs(x = "Feature", y = "Corrélation", fill = "Performance") +
  ggtitle("Importance des features dans la performance de la musique sur Spotify")
```

On peut désormais classer plus facilement les différentes features en ordre d'importance : *Loudness* puis *Acousticness* puis *Instrumentalness*. \
Cependant, ces valeurs restent faibles (environ 10% de corrélation) : il n'y a donc pas de recette miracle pour percer sur Spotify !

Regardons maintenant ce qu'il en est sur Youtube. On souhaite regarder ici la corrélation entre les différentes features et le nombre de vues, de likes et de commentaires :

```{r message=FALSE, warning=FALSE}
correlation <- youtube_dataset %>%
  cor(method = "pearson") %>%
  as.table() %>%
  as.data.frame() %>%
  mutate(value = abs(Freq))
correlation %>%
  ggplot(aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_viridis_c(option = "inferno") +
  theme(
    axis.title = element_blank(),
    axis.text.x = element_text(angle = 90, vjust = 0.4, hjust = 0.9),
    plot.title = element_text(size = 12)
  ) +
  ggtitle("Corrélation entre les différentes features et les performances sur Youtube") +
  labs(fill = "Indice de\ncorrélation")
```

On remarque deux choses :

- il va falloir réfléchir à notre indicateur de succès puisque les likes et les vues sont plus corrélées entre elles qu'avec le nombre de commentaires
- les features qui semblent les plus impactantes sur la performance d'une musique sont, comme sur Spotify, l'intensité sonore, l'acoustique, l'instrumentalité avec le côté dansant de la musique.

De la même façon que précédemment, on affiche la corrélation entre les différentes features et nos indicateurs de performance :

```{r message=FALSE, warning=FALSE}
columns <- c("Stream", "Views", "Likes", "Comments")
correlation %>%
  filter(Var1 %in% columns & !Var2 %in% columns) %>%
  ggplot(aes(x = Var2, y = value, fill = Var1)) +
  geom_bar(position = "dodge", stat = "identity") +
  theme(
    axis.text.x = element_text(angle = 90, vjust = 0.4, hjust = 0.9),
    plot.title = element_text(size = 12)
  ) +
  labs(x = "Feature", y = "Corrélation", fill = "Performance") +
  ggtitle("Importance des features dans la performance de la musique sur Youtube")
```

Le côté dansant de la musique arrive en $2^e$ position, et semble donc plus important que sur Spotify. Cela dit, cela reste à nuancer puisque la corrélation reste très faible. Ainsi, comme sur Spotify, nous n'avons pas encore trouvé la recette du succès sur Youtube.

**Observations diverses**

Nous avons constaté différentes choses intéressantes dans ces visualisations:

* les critères de performance sur Youtube ne sont pas corrélés entre eux de manière égale
* certaines features semblent corrélées entre elles (par exemple energy/loudness, energy/acousticness, acousticness/loudness)
* le calcul de la corrélation sur les `Key` ne fonctionne pas correctement. En effet, ce sont des valeurs numériques et la corrélation est donc calculée en ordonnant les tonalités. Pour mieux comprendre l'impact de la tonalité sur le succès, il peut être pertinent de se référer à la fin de la [question 4](#question-4-quelle-est-la-tonalité-la-plus-fréquente-dans-les-chansons-du-dataset).



### Question 10 : Quelle est la relation entre la présence d’un contenu sous licence et le nombre de vues ?

**Hypothèse**

On peut supposer que les musiques sous licence ont plus de vues que les musiques sans licence. En effet, les musiques sous licence sont souvent des musiques populaires, qui ont été diffusées à la radio ou à la télévision, et qui ont donc plus de chances d'être vues par un plus grand nombre de personnes.

**Visualisation**

Nous allons créer un graphique qui compare le nombre de vues des musiques sous licence et des musiques sans licence. Pour cela, nous allons utiliser un boxplot.

```{r message=FALSE, warning=FALSE}
plot_boxplot(
  dataset %>% select(Licensed, Views) %>% na.omit(),
  "Licensed", "Views",
  "Type de chanson", "Nombre de vues (log)",
  "Comparaison des vues des musiques", " sous licence et sans licence"
) +
  scale_x_discrete(labels = c("TRUE" = "Sous licence", "FALSE" = "Non licenciée"))
```



### Question 11 : Est-ce qu’un compte YouTube officiel est plus populaire qu’un compte fan ?

**Hypothèse**  

On suppose que les comptes officiels sont plus populaires (plus de Likes) que les comptes fans.

**Traitement des données**

Pour chaque artiste, on considère le compte comme "officiel" si au moins la moitié de ses vidéos ont `official_video == TRUE`. Sinon, il est classé comme "fan".  
On compare ensuite la popularité (Likes) des vidéos selon le type de compte.

```{r question12_officiel_vs_fan, message=FALSE, warning=FALSE}
# Détermination du type de compte pour chaque artiste
artiste_type <- dataset %>%
  group_by(Channel) %>%
  summarise(
    n = n(),
    n_official = sum(official_video == TRUE, na.rm = TRUE)
  ) %>%
  mutate(Type_compte = ifelse(n_official >= n / 2, "Officiel", "Fan"))

# Ajout de la variable Type_compte au dataset
dataset_type <- dataset %>%
  left_join(artiste_type %>% select(Channel, Type_compte), by = "Channel") %>%
  filter(!is.na(Type_compte), !is.na(Likes), Likes > 0)

# Boxplot Likes par type de compte
library(ggplot2)
library(scales)
ggplot(dataset_type, aes(x = Type_compte, y = Likes, fill = Type_compte)) +
  geom_boxplot(outlier.shape = NA, alpha = 0.7) +
  scale_y_log10(labels = label_number(scale_cut = cut_short_scale())) +
  stat_summary(
    fun = median, geom = "text", aes(label = scales::comma(round(..y..))),
    vjust = -0.7, color = "black", size = 5
  ) +
  labs(
    title = "Popularité des comptes YouTube officiels vs fans",
    x = "Type de compte YouTube",
    y = "Nombre de Likes (échelle log)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16, face = "bold", hjust = 0.5),
    axis.title = element_text(size = 13),
    axis.text = element_text(size = 11),
    legend.position = "none"
  )
```

**Observation**

Le boxplot ci-dessus montre la distribution du nombre de Likes pour les comptes officiels et fans.  
On constate que les comptes officiels ont une médiane de Likes plus élevée, ce qui confirme l’hypothèse d’une plus grande popularité.  
L’échelle logarithmique permet de mieux visualiser la dispersion et les valeurs extrêmes.



### Question 12 : Quel artiste est le plus populaire au moment du 7 février 2023 ?  

Nous allons analyser cela selon :

- le nombre de vues sur YouTube
- le nombre d'écoutes sur Spotify
- une moyenne combinée des deux plateformes

**Hypothèse**

On peut imaginer que certains artistes sont beaucoup plus populaires sur une plateforme que sur l’autre, selon le public visé.

**Traitement des données**

Le datasetset contient 2079 artistes uniques, il est donc préférable d'afficher uniquement les **50 artistes les plus populaires** pour garder des graphiques lisibles.

On constate aussi que certains individus n'ont pas d'url Youtube, ce qui pourrait compromettre la comparaison vues/streams

```{r message=FALSE, warning=FALSE}
# nb total de musiques
total_musiques <- nrow(dataset)
# nb d'individus sans vidéos youtube
total_sans_ytb <- nrow(dataset[dataset$Url_youtube == "", ])
# % d'individus sans vidéos youtube
pourcentage_sans_ytb <- (total_sans_ytb / total_musiques) * 100

cat("Nombre total de musiques :", total_musiques, "\n")
cat("Nombre de musiques sans vidéos YouTube :", total_sans_ytb, "\n")
cat("Pourcentage de musiques sans vidéos YouTube :", round(pourcentage_sans_ytb, 2), "%\n")
```

Étant donné que seulement $2,27%$ des musiques ne disposent pas de données YouTube, nous avons décidé de les supprimer sans risque d'altérer l'analyse globale.

```{r message=FALSE, warning=FALSE}
# Suppression des musiques sans URL YouTube
dataset <- dataset[dataset$Url_youtube != "", ]
total_musiques <- nrow(dataset)
cat("Nombre total de musiques après suppression :", total_musiques, "\n")
```

**Visualisations**

```{r question13_stacked_horizontal, message=FALSE, warning=FALSE, fig.height=12, fig.width=10, dpi=110}
library(dplyr)
library(tidyr)
library(ggplot2)

# Top 20 YouTube
top_yt <- dataset %>%
  group_by(Artist) %>%
  summarise(Total_Views = sum(Views, na.rm = TRUE)) %>%
  arrange(desc(Total_Views)) %>%
  slice_head(n = 20)

# Top 20 Spotify
top_sp <- dataset %>%
  group_by(Artist) %>%
  summarise(Total_Streams = sum(Stream, na.rm = TRUE)) %>%
  arrange(desc(Total_Streams)) %>%
  slice_head(n = 20)

# Fusion sans doublons
top_artists <- union(top_yt$Artist, top_sp$Artist)

# Récupération des valeurs pour chaque artiste
top_df <- dataset %>%
  filter(Artist %in% top_artists) %>%
  group_by(Artist) %>%
  summarise(
    Vues_YouTube = sum(Views, na.rm = TRUE),
    Ecoutes_Spotify = sum(Stream, na.rm = TRUE)
  ) %>%
  mutate(Score_combine = Vues_YouTube + Ecoutes_Spotify) %>%
  arrange(desc(Score_combine))

# Passage au format long
top_long <- top_df %>%
  pivot_longer(
    cols = c(Vues_YouTube, Ecoutes_Spotify),
    names_to = "Plateforme",
    values_to = "Valeur"
  )

# Renommage pour la légende
top_long$Plateforme <- factor(top_long$Plateforme,
  levels = c("Ecoutes_Spotify", "Vues_YouTube"),
  labels = c("Spotify", "YouTube")
)

# Stacked barplot horizontal avec valeurs affichées
ggplot(top_long, aes(
  y = reorder(Artist, top_df$Score_combine[match(Artist, top_df$Artist)]),
  x = Valeur / 1e6,
  fill = Plateforme
)) +
  geom_bar(stat = "identity") +
  geom_text(
    aes(label = round(Valeur / 1e6, 1)),
    position = position_stack(vjust = 0.5),
    size = 3, color = "black"
  ) +
  labs(
    title = "Top artistes (YouTube & Spotify) : Popularité cumulée par plateforme",
    y = "Artiste",
    x = "Nombre (en millions)",
    fill = "Plateforme"
  ) +
  scale_fill_manual(values = c("Spotify" = "#1ED760", "YouTube" = "#FF0000")) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 9),
    axis.text.x = element_text(size = 10),
    plot.margin = margin(10, 30, 10, 10)
  )
```

On obtient une vision plus complète de la popularité des artistes.
Certains artistes dominent les deux plateformes de manière équilibrée, tandis que d'autres sont clairement plus forts sur une seule plateforme.

Au sommet du classement on trouve Ed Sheeran avec presque 30 milliards d'interactions, en tête sur les deux plateformes individuellement.
Des stars internationales remplissent le sommet du top : Justin Bieber, Coldplay, Post Malone Dua Lipa ...

**Observations diverses**

- Katy Perry ($9^e$ combiné) est beaucoup plus forte sur YouTube que sur Spotify (typé vidéo/Youtube).
- Post Malone ($4^e$ combiné) a plus du double de streams Spotify que de vues YouTube (typé audio/Spotify).
- Luis Fonsi et Daddy Yankee : leur classement est boosté par d'énormes succès vidéo (ex: Despacito) mais leur streaming audio pur est plus faible.
- CoComelon (contenu enfant) : extrêmement populaire sur YouTube, beaucoup moins sur Spotify (presque anecdotique en streaming pur).
- Certains artistes comme Coldplay, Imagine Dragons ou encore Bruno Mars performent de façon équilibrée entre plateformes.

La liste montre une très forte dominance de la pop et du hip-hop/RnB mais aussi de quelques artistes de musique latine.

Nous allons analyser les artistes qui figurent uniquement dans l’un des deux classements, cette comparaison permettra de mettre en évidence les artistes qui bénéficient d'une popularité très marquée sur une seule plateforme. (On met le rang)

```{r comparaison_top50, message=FALSE, warning=FALSE, fig.height=6, fig.width=14, dpi=300}
# Top 50 artistes par vues YouTube
top_views <- dataset %>%
  group_by(Artist) %>%
  summarise(Total_Views = sum(Views, na.rm = TRUE)) %>%
  arrange(desc(Total_Views)) %>%
  slice_head(n = 50)

# Top 50 artistes par streams Spotify
top_streams <- dataset %>%
  group_by(Artist) %>%
  summarise(Total_Streams = sum(Stream, na.rm = TRUE)) %>%
  arrange(desc(Total_Streams)) %>%
  slice_head(n = 50)

# Artistes dans le top Spotify mais PAS dans le top YouTube
spotify_only <- setdiff(top_streams$Artist, top_views$Artist)

# Artistes dans le top YouTube mais PAS dans le top Spotify
youtube_only <- setdiff(top_views$Artist, top_streams$Artist)

# Données pour Spotify only
spotify_only_dataset <- dataset %>%
  filter(Artist %in% spotify_only) %>%
  group_by(Artist) %>%
  summarise(Total_Views = sum(Views, na.rm = TRUE)) %>%
  arrange(desc(Total_Views))

# Données pour YouTube only
youtube_only_dataset <- dataset %>%
  filter(Artist %in% youtube_only) %>%
  group_by(Artist) %>%
  summarise(Total_Streams = sum(Stream, na.rm = TRUE)) %>%
  arrange(desc(Total_Streams))

# Premier graphique : Spotify only (vues YouTube)
ggplot(spotify_only_dataset, aes(Total_Views / 1e6, reorder(Artist, Total_Views))) +
  geom_point(size = 3, color = "steelblue") +
  geom_text(aes(label = round(Total_Views / 1e6, 1)), hjust = -0.5, size = 2.5) +
  labs(
    title = "Artistes Top 50 Spotify (hors Top 50 YouTube)",
    x = "Nombre de vues YouTube (en millions)",
    y = "Artiste"
  ) +
  scale_x_continuous(labels = comma, expand = expansion(mult = c(0, 0.15))) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 6),
    axis.text.x = element_text(size = 10),
    plot.margin = margin(10, 40, 10, 10)
  )

# Deuxième graphique : YouTube only (streams Spotify)
ggplot(youtube_only_dataset, aes(Total_Streams / 1e6, reorder(Artist, Total_Streams))) +
  geom_point(size = 3, color = "darkorange") +
  geom_text(aes(label = round(Total_Streams / 1e6, 1)), hjust = -0.5, size = 2.5) +
  labs(
    title = "Artistes Top 50 YouTube (hors Top 50 Spotify)",
    x = "Nombre d'écoutes Spotify (en millions)",
    y = "Artiste"
  ) +
  scale_x_continuous(labels = comma, expand = expansion(mult = c(0, 0.15))) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 6),
    axis.text.x = element_text(size = 10),
    plot.margin = margin(10, 40, 10, 10)
  )
```

On voit en bas de chaque classement les artistes qui ont de grosses disparités d'interaction entre les plateformes.
Parmi les artistes du top stream, on voit qu'Olivia Rodrigo ou Doja Cat ont beaucoup moins d'interactions sur YouTube.
Au contraire, on voit que des artistes ayant un fort succès sur YouTube comme CoComelon ou PSY ont des performances bien moindres sur Spotify.

Cette question est egalement traitée avec un dashboard Shiny, dans lequel il est possible de retrouvé les differentes formation en fonction la plateforme choisie, mais elgament les 2 graphiques.

### Conclusion de la partie "Impact sur le succès"

Nous avons vu dans cette deuxième partie que :

- les morceaux lives pourraient être plus populaires sur Youtube que sur Spotify mais le dataset est trop peu fourni pour pouvoir l'affirmer
- les vidéos officielles (sur youtube) sont plus regardées que les vidéos non officielles
- les musiques sous licence génèrent plus de vues que les musiques sans licence
- la publication sur un compte officiel est accompagné de plus de likes que sur un compte non officiel. Il peut être important de faire certifier son compte par les plateformes comme Youtube et Spotify
- il y a peu de corrélation entre les caractéristiques quantifiables des musiques et leur succès, aussi bien sur Youtube que sur Spotify
- certains artistes dominent les deux plateformes de streaming musical mais ce n'est pas du tout une tendance générale, certains sont présents quasimment exclusivement sur l'une des deux plateformes

---

## Clustering

Dans cette partie, nous allons tenter de trouver des clusters de musiques, de voir si leurs caractéristiques permettent de les regrouper par exemple par genre musical, etc.

### Question 13 : Peut-on visualiser des clusters de chansons selon leurs caractéristiques avec la t-SNE ?

**Hypothèse**

Nous cherchons à regrouper les chansons selon leurs caractéristiques musicales (énergie, valence, danceability, etc.) pour voir si des familles musicales cohérentes émergent.

**Traitement des données**

Pour ce clustering, nous avons sélectionné les variables numériques suivantes, qui décrivent la structure musicale des morceaux :

- Tempo (battements par minute) : rythme du morceau
- Valence : score d’émotion positive
- Liveness : probabilité d’enregistrement live
- Loudness : volume moyen
- Danceability : score de dansabilité
- Key : tonalité (codée en entier)
- Stream : nombre d’écoutes Spotify (utilisé uniquement pour la description et les tooltips, pas pour le clustering)
Ces variables ont été choisies car elles permettent de capturer la diversité musicale : rythme, ambiance, tonalité, caractère live ou studio, et potentiel de danse. Nous avons retiré les valeurs manquantes et les doublons pour garantir la qualité de l’analyse. La variable Stream n’a pas été utilisée pour le clustering, car elle reflète la popularité et non la nature musicale du morceau.

**Visualisations**

```{r question14_umap_dbscan, message=FALSE, warning=FALSE, echo=FALSE}
library(dplyr)
library(umap)
library(dbscan)
library(plotly)
library(FNN)
library(RColorBrewer)

set.seed(42)

# 1. Sélection et échantillonnage
cluster_data <- dataset %>%
  select(Tempo, Valence, Liveness, Loudness, Danceability, Key, Stream, Track, Artist, Energy, Acousticness, Instrumentalness, Duration_ms, Uri) %>%
  na.omit()

if (nrow(cluster_data) > 2000) {
  idx <- sample(nrow(cluster_data), 2000)
  cluster_data <- cluster_data[idx, ]
}

features <- cluster_data %>%
  select(Tempo, Valence, Liveness, Loudness, Danceability, Key, Stream)

# 2. UMAP
umap_config <- umap.defaults
umap_config$n_neighbors <- 15
umap_config$min_dist <- 0.1
umap_config$random_state <- 42

umap_result <- umap(as.matrix(features), config = umap_config)
umap_df <- as.data.frame(umap_result$layout)
colnames(umap_df) <- c("UMAP1", "UMAP2")

# 3. Recherche automatique d'epsilon pour DBSCAN (méthode du kNN)
k <- 10
knn_dist <- FNN::knn.dist(umap_df, k = k)
eps_auto <- quantile(knn_dist[, k], 0.98) # 98e percentile

# 4. DBSCAN sur UMAP
db <- dbscan(umap_df, eps = eps_auto, minPts = k)
umap_df$Cluster <- factor(db$cluster)
umap_df$Track <- cluster_data$Track
umap_df$Artist <- cluster_data$Artist

# Pour résumé automatique, on rattache les clusters à cluster_data
cluster_data$Cluster <- umap_df$Cluster

# 5. Résumé automatique par cluster (hors outliers)
dataset_clustered_nodup <- cluster_data %>% filter(Cluster != 0)
summary_table <- dataset_clustered_nodup %>%
  group_by(Cluster) %>%
  summarise(
    n = n(),
    Energy = mean(Energy, na.rm = TRUE),
    Danceability = mean(Danceability, na.rm = TRUE),
    Acousticness = mean(Acousticness, na.rm = TRUE),
    Instrumentalness = mean(Instrumentalness, na.rm = TRUE),
    Tempo = mean(Tempo, na.rm = TRUE),
    Duration = mean(Duration_ms, na.rm = TRUE) / 1000 # en secondes
  )

cat("Résumé automatique par cluster :\n\n")
print(summary_table)

# 6. Visualisation interactive
umap_df$hover <- paste0(
  "<b>", umap_df$Track, "</b><br>",
  "Artiste : ", umap_df$Artist, "<br>",
  "Cluster : ", umap_df$Cluster
)

cols <- c(RColorBrewer::brewer.pal(8, "Set2"), "grey70")
n_clust <- length(unique(umap_df$Cluster))
palette_size <- max(n_clust, 9)
cols <- c(colorRampPalette(RColorBrewer::brewer.pal(8, "Set2"))(palette_size), "grey70")
col_scale <- setNames(cols[seq_len(n_clust)], sort(unique(umap_df$Cluster)))
col_scale["0"] <- "grey70" # outliers

plot_ly(
  umap_df,
  x = ~UMAP1, y = ~UMAP2,
  color = ~Cluster, colors = col_scale,
  type = "scatter", mode = "markers",
  marker = list(size = 7, opacity = 0.7),
  text = ~hover, hoverinfo = "text"
) %>%
  layout(title = "Clusters DBSCAN sur UMAP (échantillon de 2000 chansons)")
```

```{r export_clusters_uri, echo=FALSE, message=FALSE}
# Crée un dossier pour les clusters si besoin
if (!dir.exists("clusters_csv")) dir.create("clusters_csv")

# Pour chaque cluster (hors outliers si Cluster==0)
for (clust in unique(dataset_clustered_nodup$Cluster)) {
  if (clust == 0) next # on saute les outliers si besoin
  tracks <- dataset_clustered_nodup %>%
    filter(Cluster == clust) %>%
    select(Uri, Track, Artist, Cluster)
  write.csv(tracks, file = paste0("clusters_csv/cluster_", clust, ".csv"), row.names = FALSE, fileEncoding = "UTF-8")
}
```

La méthode (UMAP + DBSCAN) permet de regrouper les chansons en clusters dans l’espace réduit, mais à l’analyse, ces clusters n’ont pas vraiment de sens musical évident. Plusieurs facteurs expliquent ce résultat :

- Qualité discutable de certaines features : Les variables comme valence ou energy sont issues d’algorithmes propriétaires de Spotify et peuvent être calculées de façon peu transparente ou peu fiable. Par exemple, certaines musiques de bruit blanc se retrouvent avec une instrumentalness et une loudness très élevées, ce qui ne correspond pas à une réalité musicale pertinente.
- Présence d’outliers thématiques : Le dataset contient des objets très atypiques, comme des contes pour enfants en allemand ou des sons expérimentaux, qui faussent la structure des groupes.
- Clusters peu interprétables : Le tableau récapitulatif des clusters montre des moyennes de features assez proches d’un cluster à l’autre, sans qu’on puisse vraiment identifier des “familles” musicales claires (par exemple : pas de cluster “très dansant”, “très calme”, etc.).

En conlusion, même si la méthode de clustering permet de regrouper les chansons, la pertinence musicale des groupes reste limitée, principalement à cause de la qualité et de l’hétérogénéité des features utilisées. Pour obtenir des clusters plus cohérents, il serait nécessaire d’utiliser des features plus fiables ou de filtrer davantage le dataset pour écarter les cas atypiques.


# Conclusion

La conclusion de notre étude est mitigée : nous avons réussi à faire ressortir quelques tendances mais il semblerait que notre dataset ne soit pas assez complet.
A l'issue de cette analyse, nous sommes capables de dire avec certitude que les comptes certifiés/officiels et les vidéos officielles/musiques sous licence sont plus populaires, mais n'est ce pas plutôt leur popularité qui a mené à la certification des comptes et à la classification en tant que "vidéo officielle" ? Il est probable que si, même à postériori pour certaines d'entre elles.
En tout cas, ce sont les seules données qui se détachent vraiment du lot pour expliquer le succès des musiques, donc nous n'avons pas vraiment trouvé de critère pour qu'une musique apparaisse dans le billboard spotify ou dans les tendances musicales de youtube.

Cela dit, nous avons pu observer la répartition de plusieurs caractéristiques des chansons et les corrélations entre elles. Nous avons pu constater qu'elles étaient en accord ou non avec d'autres études précédentes que nous avons pu trouver sur internet.
Pour ce qui est du clustering, nous n'avons pas réussi à regrouper les chansons de manière pertinente. Ceci à cause notamment de défauts de notre dataset.

## Pourquoi le dataset est-il difficilement exploitable ?

### Le calcul des features est opaque :
Nous ne savons pas comment elles ont été calculées. Nous ont parfois été surpris en écoutant les musiques et nous avons trouvé que la valeur ne correspondait pas toujours à l'audio que nous avions écouté.

### Le dataset contient des audios qui ne sont pas des musiques :
Le dataset inclut également des fichiers audios et youtube et spotify qui ne sont pas des musiques mais du bruit blanc ou encore des livres audio. Difficile de mener une étude sur des musiques quand de tels outliers se fondent dans le dataset.

### Le dataset n'inclut que les "meilleures musiques" des artistes :
Nous n'avons pas, dans cette étude, une vue assez complète sur paysage musical puisque nous ne nous intéressons qu'aux meilleures musiques des artistes, alors que certaines de leurs autres musiques marchent mieux que les meilleurs musiques d'autres artistes moins populaires. Il aurait été interssant de ne pas restreindre le dataset intial en fixant un nombre de musiques par artiste mais plutôt en fixant un seuil minimal de likes/streams/vues.

## Perspectives
Pour aller plus loin, plusieurs pistes d'amélioration peuvent être envisagées :

- **Amélioration des données :** Utiliser des features plus fiables et pertinentes pour mieux capturer les caractéristiques musicales des chansons.
- **Filtrage des outliers :** Écarter les objets atypiques pour obtenir des analyses plus cohérentes.
- **Approches complémentaires :** Explorer d'autres méthodes de clustering ou intégrer des données qualitatives (par exemple, des genres musicaux ou des annotations humaines).
- **Analyse temporelle :** Étudier l'évolution des performances des chansons sur les deux plateformes pour identifier des tendances ou des cycles de popularité.

En conclusion, ce projet a permis de mettre en lumière des tendances intéressantes et des limites méthodologiques, tout en ouvrant la voie à des analyses plus approfondies et ciblées. Les résultats obtenus constituent une base solide pour mieux comprendre les dynamiques de succès sur Spotify et YouTube, et pour orienter les stratégies des artistes et des producteurs de contenu.

## Conclusions personnelles :

### Klimentiy
Ce que j’ai retenu, la diversité de la data visualisation. Ce projet m’a permis d’explorer les différentes types de dataviz, et de comprendre comment les mettre en place. Ce que j’aurais aimé de faire en plus, c’est d’analyser les chansons en fonction du style de la chanson.

### Paul
J'ai beaucoup appris de ce projet, notamment sur le choix des visualisations, qui sont déterminantes pour une bonne compréhension des données. Cependant, j'aurais aimé pouvoir avoir plus de caractéristiques sur les chansons, et surtout comprendre comment elles ont été réalisées.

### Alban
Le projet m'a permis de trouver un cas d'application pratique *(autre que faire un graphique pour faire un graphique)* où le choix de visualisation est vraiment important. Je trouve dommage que le dataset contienne de données aussi peu interpétable et j'aurais sans douté aimé recommencer la même analyse avec des données différentes/un dataset différent.

### Thomas


# Annexes

## Annexe 1 : Répartition du travail au sein du groupe

Pour ce qui est de la présentation (notamment les slides), nous avons tous participé à sa création. Voici la répartition des sujets traités de manière plus individuelle :

| **Membre**  | **Travail effectué** |
| :--: | :------------ |
| Klimentiy | Question 1, question 3, question 5, dashboard shiny et de petites améliorations du rapport (eg. le changement d'ordre des questions) |
| Alban | Questions 2, 4, 8 et 9. J'ai également ajouté la génération des images en png/fond transparent pour les slides (il faudra installer `orca` pour que ça fonctionne sur certains graphiques). J'ai rédigé les conlusions des parties 1 et 2 et fait quelques améliorations sur le rapport (en plus de corriger les fautes d'orthographe). J'ai également fait les graphes et dashboards sur Tableau. |
| Thomas | Questions 12, 13 et 14. J'ai réalisé l'analyse de l'impact d'un compte officiel sur le succès des vidéos YouTube, exploré les artistes les plus populaires sur Spotify et YouTube, et mis en place le clustering des chansons avec UMAP et DBSCAN. J'ai également contribué à la rédaction des observations et conclusions pour ces analyses. |
| Paul | Questions 6, 7, 10 et readme *(proposition du jeu de données)* |
